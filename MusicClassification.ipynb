{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "#print\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "#looping and creating path for every genres \n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    \n",
    "    #mapping\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):    #folder names are being genereated.....still in folder\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rmse(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)        \n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>0.349943</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>1784.420446</td>\n",
       "      <td>2002.650192</td>\n",
       "      <td>3806.485316</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>-113.596742</td>\n",
       "      <td>121.557302</td>\n",
       "      <td>-19.158825</td>\n",
       "      <td>...</td>\n",
       "      <td>8.810668</td>\n",
       "      <td>-3.667367</td>\n",
       "      <td>5.751690</td>\n",
       "      <td>-5.162761</td>\n",
       "      <td>0.750947</td>\n",
       "      <td>-1.691937</td>\n",
       "      <td>-0.409954</td>\n",
       "      <td>-2.300208</td>\n",
       "      <td>1.219928</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>0.340983</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>1529.835316</td>\n",
       "      <td>2038.617579</td>\n",
       "      <td>3548.820207</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>-207.556796</td>\n",
       "      <td>124.006717</td>\n",
       "      <td>8.930562</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376802</td>\n",
       "      <td>-2.239119</td>\n",
       "      <td>4.216963</td>\n",
       "      <td>-6.012273</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>-0.716537</td>\n",
       "      <td>0.293875</td>\n",
       "      <td>-0.287431</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>1552.481958</td>\n",
       "      <td>1747.165985</td>\n",
       "      <td>3040.514948</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>-90.754394</td>\n",
       "      <td>140.459907</td>\n",
       "      <td>-29.109965</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789265</td>\n",
       "      <td>-8.905224</td>\n",
       "      <td>-1.083720</td>\n",
       "      <td>-9.218359</td>\n",
       "      <td>2.455805</td>\n",
       "      <td>-7.726901</td>\n",
       "      <td>-1.815724</td>\n",
       "      <td>-3.433434</td>\n",
       "      <td>-2.226821</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.141191</td>\n",
       "      <td>1070.119953</td>\n",
       "      <td>1596.333948</td>\n",
       "      <td>2185.028454</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>-199.431144</td>\n",
       "      <td>150.099218</td>\n",
       "      <td>5.647594</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087676</td>\n",
       "      <td>-2.476420</td>\n",
       "      <td>-1.073890</td>\n",
       "      <td>-2.874777</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>-3.316932</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>-0.619690</td>\n",
       "      <td>-3.408233</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>1835.494603</td>\n",
       "      <td>1748.362448</td>\n",
       "      <td>3580.945013</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>-160.266031</td>\n",
       "      <td>126.198800</td>\n",
       "      <td>-35.605448</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806385</td>\n",
       "      <td>-6.934122</td>\n",
       "      <td>-7.558619</td>\n",
       "      <td>-9.173552</td>\n",
       "      <td>-4.512166</td>\n",
       "      <td>-5.453538</td>\n",
       "      <td>-0.924162</td>\n",
       "      <td>-4.409333</td>\n",
       "      <td>-11.703781</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00000.wav     0.349943  0.130225        1784.420446   \n",
       "1  blues.00001.wav     0.340983  0.095918        1529.835316   \n",
       "2  blues.00002.wav     0.363603  0.175573        1552.481958   \n",
       "3  blues.00003.wav     0.404779  0.141191        1070.119953   \n",
       "4  blues.00004.wav     0.308590  0.091563        1835.494603   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2002.650192  3806.485316            0.083066 -113.596742   \n",
       "1         2038.617579  3548.820207            0.056044 -207.556796   \n",
       "2         1747.165985  3040.514948            0.076301  -90.754394   \n",
       "3         1596.333948  2185.028454            0.033309 -199.431144   \n",
       "4         1748.362448  3580.945013            0.101500 -160.266031   \n",
       "\n",
       "        mfcc2      mfcc3  ...    mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0  121.557302 -19.158825  ...  8.810668 -3.667367  5.751690 -5.162761   \n",
       "1  124.006717   8.930562  ...  5.376802 -2.239119  4.216963 -6.012273   \n",
       "2  140.459907 -29.109965  ...  5.789265 -8.905224 -1.083720 -9.218359   \n",
       "3  150.099218   5.647594  ...  6.087676 -2.476420 -1.073890 -2.874777   \n",
       "4  126.198800 -35.605448  ... -2.806385 -6.934122 -7.558619 -9.173552   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  label  \n",
       "0  0.750947 -1.691937 -0.409954 -2.300208   1.219928  blues  \n",
       "1  0.936109 -0.716537  0.293875 -0.287431   0.531573  blues  \n",
       "2  2.455805 -7.726901 -1.815724 -3.433434  -2.226821  blues  \n",
       "3  0.780976 -3.316932  0.637981 -0.619690  -3.408233  blues  \n",
       "4 -4.512166 -5.453538 -0.924162 -4.409333 -11.703781  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.71278873,  0.87323919,  0.40816517,  0.08352154,  0.33902875,\n",
       "        0.58839083,  0.92753094, -0.42787394, -0.5235268 ,  1.36585626,\n",
       "       -0.79686835,  1.08936718, -0.61568045,  1.32094307, -0.5505793 ,\n",
       "        0.70015339, -0.43896028,  1.40539812, -0.96283842,  1.31995497,\n",
       "       -0.66111542,  1.54508283, -0.4858743 ,  0.85343043,  0.11026233,\n",
       "        0.51833271])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.3 in c:\\users\\scc\\appdata\\roaming\\python\\python36\\site-packages (from seaborn) (1.18.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from seaborn) (1.3.2)\n",
      "Requirement already satisfied: pandas>=0.15.2 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from seaborn) (0.25.3)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.4.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (42.0.2.post20191203)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from scikit-image) (1.3.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from scikit-image) (6.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from scikit-image) (3.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\scc\\appdata\\roaming\\python\\python36\\site-packages (from imageio>=2.3.0->scikit-image) (1.18.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\scc\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (42.0.2.post20191203)\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn\n",
    "! pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import zlib\n",
    "import itertools\n",
    "import sklearn\n",
    "import itertools\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "#from keras.applications.mobilenet import MobileNet\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import roc_curve\n",
    "#from sklearn.metrics import auc\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import model\n",
    "# from keras import layers\n",
    "# import tensorflow as tf\n",
    "#from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(tf.__version__)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "###----\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1/20\n",
    "# 800/800 [==============================] - 1s 1ms/step - loss: 2.1637 - acc: 0.2250\n",
    "# Epoch 2/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 1.8532 - acc: 0.3625\n",
    "# Epoch 3/20\n",
    "# 800/800 [==============================] - 0s 57us/step - loss: 1.6190 - acc: 0.4062\n",
    "# Epoch 4/20\n",
    "# 800/800 [==============================] - 0s 56us/step - loss: 1.4568 - acc: 0.5000\n",
    "# Epoch 5/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 1.3145 - acc: 0.5337\n",
    "# Epoch 6/20\n",
    "# 800/800 [==============================] - 0s 60us/step - loss: 1.1780 - acc: 0.6013\n",
    "# Epoch 7/20\n",
    "# 800/800 [==============================] - 0s 75us/step - loss: 1.0935 - acc: 0.6650\n",
    "# Epoch 8/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 1.0032 - acc: 0.6737\n",
    "# Epoch 9/20\n",
    "# 800/800 [==============================] - 0s 57us/step - loss: 0.9374 - acc: 0.7000\n",
    "# Epoch 10/20\n",
    "# 800/800 [==============================] - 0s 87us/step - loss: 0.8768 - acc: 0.7263\n",
    "# Epoch 11/20\n",
    "# 800/800 [==============================] - 0s 65us/step - loss: 0.8361 - acc: 0.7375\n",
    "# Epoch 12/20\n",
    "# 800/800 [==============================] - 0s 110us/step - loss: 0.7891 - acc: 0.7437\n",
    "# Epoch 13/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 0.7556 - acc: 0.7563\n",
    "# Epoch 14/20\n",
    "# 800/800 [==============================] - 0s 74us/step - loss: 0.7123 - acc: 0.7787\n",
    "# Epoch 15/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 0.6776 - acc: 0.7900\n",
    "# Epoch 16/20\n",
    "# 800/800 [==============================] - 0s 66us/step - loss: 0.6432 - acc: 0.7963\n",
    "# Epoch 17/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 0.6190 - acc: 0.8100\n",
    "# Epoch 18/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 0.5978 - acc: 0.8188\n",
    "# Epoch 19/20\n",
    "# 800/800 [==============================] - 0s 60us/step - loss: 0.5537 - acc: 0.8337\n",
    "# Epoch 20/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 0.5374 - acc: 0.8463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_classifier(clf, X_train, y_train):\n",
    "#     ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "#     # Start the clock, train the classifier, then stop the clock\n",
    "#     start = time()\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     end = time()\n",
    "    \n",
    "#     # Print the results\n",
    "#     print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "    \n",
    "# #this may not used at all    \n",
    "# def predict_labels(clf, features, target):\n",
    "#     ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "#     #################################################F1 score astesee predict_labels(...) theke \n",
    "    \n",
    "#     # Start the clock, make predictions, then stop the clock\n",
    "#     start = time()\n",
    "#   #  y_pred = clf.predict(features) ****Features is not defind for my dataset. if i can solve this line then\n",
    "# #******************************************************{NameError: name 'y_pred' is not defined} will be \n",
    "# #######################################################solved\n",
    "\n",
    "# ########################## ORIGIN CODE FIRST OCCURANCE OF FEATURES******************************\n",
    "\n",
    "# #####################filepath = 'features.csv'\n",
    "# ################features = pd.read_csv(filepath, index_col=0,header=[0, 1, 2], skip_blank_lines=True )\n",
    "\n",
    "# #--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # features is pandas read_csv dictionary \n",
    "#     end = time()\n",
    "    \n",
    "#     # Print and return results\n",
    "#     print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "#     return f1_score(target, y_pred, average='micro', pos_label = 1)\n",
    "\n",
    "\n",
    "\n",
    "# def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "#     ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "#     # Indicate the classifier and the training set size\n",
    "#     print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    " \n",
    "#     # Train the classifier\n",
    "#     train_classifier(clf, X_train, y_train)\n",
    "#        #untill now no problem\n",
    "        \n",
    "#         #### if i switched places between the train_predict and predict_labels\n",
    "    \n",
    "#     # Print the results of prediction for both training and testing\n",
    "#     #may not work.....comment out this below section\n",
    "#     print(\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "#     print(\"F1 score for val set: {:.4f}.\".format(predict_labels(clf, X_val, y_val)))\n",
    "#     print(\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyAudioAnalysis import audioBasicIO\n",
    "# from pyAudioAnalysis import ShortTermFeatures\n",
    "\n",
    "\n",
    "# for g in genres:\n",
    "#     pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "#     for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "#         songname = f'./MIR/genres/{g}/{filename}'\n",
    "#         y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "#         plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "#         plt.axis('off');\n",
    "#         plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "#         plt.clf()\n",
    "\n",
    "# [Fs, x] = audioBasicIO.read_audio_file(\"sample.wav\")\n",
    "# F, f_names = ShortTermFeatures.feature_extraction(x, Fs, 0.050*Fs, 0.025*Fs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# #from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # TODO: Initialize the three models\n",
    "# clf_A = DecisionTreeClassifier(random_state=10, max_depth =4)\n",
    "# clf_B = SVC()\n",
    "# clf_C = LogisticRegression()\n",
    "# clf_D = RandomForestClassifier(random_state=10, max_depth=30, n_estimators=300, min_samples_leaf=6, min_impurity_decrease=0.0002,\n",
    "#                      class_weight='balanced')\n",
    "\n",
    "# for clf in [clf_A, clf_B, clf_C, clf_D]:\n",
    "#     print(\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "#     train_predict(clf, X_train, y_train, X_test, y_test)   # X_val turned to X_test, y_val to y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification of Music into different Genres using Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import csv# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler#Keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###create a CSV file\n",
    "\n",
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###calculate all the features.\n",
    "\n",
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    #for filename in os.listdir(f'./genres/{g}'):              ###############Eroor****FileNotFoundError: [WinError 3] The system cannot find the path specified: './genres/blues'\n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)   ###errror****FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\SCC\\\\genres\\\\blues\\\\blues.00000.wav'\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rmse(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n",
    "            \n",
    "            \n",
    "            \n",
    "            #ran with out an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, : -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######np.array(data.iloc[:, : -1] , dtype = float) ##########here's the error\n",
    "\n",
    "####np.array(data.iloc[:, : -1] , dtype.astype = float)\n",
    "\n",
    "np.array(data.iloc[:, : -1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "#convertion\n",
    "x = np.array(data.iloc[:, :-1])\n",
    "Y = x.astype(np.float)\n",
    "\n",
    "\n",
    "X = scaler.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X into dataframe\n",
    "X_pd = pd.DataFrame(data=x)\n",
    "# replace all instances of URC with 0 \n",
    "X_replace = for item in X_pd:\n",
    "                \n",
    "                X_pd.replace(f'rock.000{num}.wav',0, regex=True)\n",
    "\n",
    "# # convert it back to numpy array\n",
    "X_np = X_replace.values\n",
    "# # set the object type as float\n",
    "X_fa = X_np.astype(dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
