{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    \n",
    "    #mapping\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):    #folder names are being genereated.....still in folder\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rmse(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)        \n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>0.349943</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>1784.420446</td>\n",
       "      <td>2002.650192</td>\n",
       "      <td>3806.485316</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>-113.596742</td>\n",
       "      <td>121.557302</td>\n",
       "      <td>-19.158825</td>\n",
       "      <td>...</td>\n",
       "      <td>8.810668</td>\n",
       "      <td>-3.667367</td>\n",
       "      <td>5.751690</td>\n",
       "      <td>-5.162761</td>\n",
       "      <td>0.750947</td>\n",
       "      <td>-1.691937</td>\n",
       "      <td>-0.409954</td>\n",
       "      <td>-2.300208</td>\n",
       "      <td>1.219928</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>0.340983</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>1529.835316</td>\n",
       "      <td>2038.617579</td>\n",
       "      <td>3548.820207</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>-207.556796</td>\n",
       "      <td>124.006717</td>\n",
       "      <td>8.930562</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376802</td>\n",
       "      <td>-2.239119</td>\n",
       "      <td>4.216963</td>\n",
       "      <td>-6.012273</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>-0.716537</td>\n",
       "      <td>0.293875</td>\n",
       "      <td>-0.287431</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>1552.481958</td>\n",
       "      <td>1747.165985</td>\n",
       "      <td>3040.514948</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>-90.754394</td>\n",
       "      <td>140.459907</td>\n",
       "      <td>-29.109965</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789265</td>\n",
       "      <td>-8.905224</td>\n",
       "      <td>-1.083720</td>\n",
       "      <td>-9.218359</td>\n",
       "      <td>2.455805</td>\n",
       "      <td>-7.726901</td>\n",
       "      <td>-1.815724</td>\n",
       "      <td>-3.433434</td>\n",
       "      <td>-2.226821</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.141191</td>\n",
       "      <td>1070.119953</td>\n",
       "      <td>1596.333948</td>\n",
       "      <td>2185.028454</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>-199.431144</td>\n",
       "      <td>150.099218</td>\n",
       "      <td>5.647594</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087676</td>\n",
       "      <td>-2.476420</td>\n",
       "      <td>-1.073890</td>\n",
       "      <td>-2.874777</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>-3.316932</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>-0.619690</td>\n",
       "      <td>-3.408233</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>1835.494603</td>\n",
       "      <td>1748.362448</td>\n",
       "      <td>3580.945013</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>-160.266031</td>\n",
       "      <td>126.198800</td>\n",
       "      <td>-35.605448</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806385</td>\n",
       "      <td>-6.934122</td>\n",
       "      <td>-7.558619</td>\n",
       "      <td>-9.173552</td>\n",
       "      <td>-4.512166</td>\n",
       "      <td>-5.453538</td>\n",
       "      <td>-0.924162</td>\n",
       "      <td>-4.409333</td>\n",
       "      <td>-11.703781</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00000.wav     0.349943  0.130225        1784.420446   \n",
       "1  blues.00001.wav     0.340983  0.095918        1529.835316   \n",
       "2  blues.00002.wav     0.363603  0.175573        1552.481958   \n",
       "3  blues.00003.wav     0.404779  0.141191        1070.119953   \n",
       "4  blues.00004.wav     0.308590  0.091563        1835.494603   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2002.650192  3806.485316            0.083066 -113.596742   \n",
       "1         2038.617579  3548.820207            0.056044 -207.556796   \n",
       "2         1747.165985  3040.514948            0.076301  -90.754394   \n",
       "3         1596.333948  2185.028454            0.033309 -199.431144   \n",
       "4         1748.362448  3580.945013            0.101500 -160.266031   \n",
       "\n",
       "        mfcc2      mfcc3  ...    mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0  121.557302 -19.158825  ...  8.810668 -3.667367  5.751690 -5.162761   \n",
       "1  124.006717   8.930562  ...  5.376802 -2.239119  4.216963 -6.012273   \n",
       "2  140.459907 -29.109965  ...  5.789265 -8.905224 -1.083720 -9.218359   \n",
       "3  150.099218   5.647594  ...  6.087676 -2.476420 -1.073890 -2.874777   \n",
       "4  126.198800 -35.605448  ... -2.806385 -6.934122 -7.558619 -9.173552   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  label  \n",
       "0  0.750947 -1.691937 -0.409954 -2.300208   1.219928  blues  \n",
       "1  0.936109 -0.716537  0.293875 -0.287431   0.531573  blues  \n",
       "2  2.455805 -7.726901 -1.815724 -3.433434  -2.226821  blues  \n",
       "3  0.780976 -3.316932  0.637981 -0.619690  -3.408233  blues  \n",
       "4 -4.512166 -5.453538 -0.924162 -4.409333 -11.703781  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4800857 , -1.21429102,  0.31126631,  1.3016359 ,  0.68175074,\n",
       "       -0.40823502, -0.74528507, -0.16569064,  2.38518197, -1.2109071 ,\n",
       "        0.8740863 , -0.1449178 ,  1.29331464, -0.73867969,  0.72088466,\n",
       "       -1.22092485,  0.59410935, -0.19550758,  0.63319084, -1.72678456,\n",
       "       -0.24567322, -1.12833371, -0.35859001, -1.42204929, -0.04996263,\n",
       "       -0.83526104])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 2.1637 - acc: 0.2250\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/step - loss: 1.8532 - acc: 0.3625\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/step - loss: 1.6190 - acc: 0.4062\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/step - loss: 1.4568 - acc: 0.5000\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/step - loss: 1.3145 - acc: 0.5337\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.1780 - acc: 0.6013\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 75us/step - loss: 1.0935 - acc: 0.6650\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.0032 - acc: 0.6737\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.9374 - acc: 0.7000\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 87us/step - loss: 0.8768 - acc: 0.7263\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.8361 - acc: 0.7375\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.7891 - acc: 0.7437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.7556 - acc: 0.7563\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.7123 - acc: 0.7787\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6776 - acc: 0.7900\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6432 - acc: 0.7963\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6190 - acc: 0.8100\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5978 - acc: 0.8188\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.5537 - acc: 0.8337\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5374 - acc: 0.8463\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1/20\n",
    "# 800/800 [==============================] - 1s 1ms/step - loss: 2.1637 - acc: 0.2250\n",
    "# Epoch 2/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 1.8532 - acc: 0.3625\n",
    "# Epoch 3/20\n",
    "# 800/800 [==============================] - 0s 57us/step - loss: 1.6190 - acc: 0.4062\n",
    "# Epoch 4/20\n",
    "# 800/800 [==============================] - 0s 56us/step - loss: 1.4568 - acc: 0.5000\n",
    "# Epoch 5/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 1.3145 - acc: 0.5337\n",
    "# Epoch 6/20\n",
    "# 800/800 [==============================] - 0s 60us/step - loss: 1.1780 - acc: 0.6013\n",
    "# Epoch 7/20\n",
    "# 800/800 [==============================] - 0s 75us/step - loss: 1.0935 - acc: 0.6650\n",
    "# Epoch 8/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 1.0032 - acc: 0.6737\n",
    "# Epoch 9/20\n",
    "# 800/800 [==============================] - 0s 57us/step - loss: 0.9374 - acc: 0.7000\n",
    "# Epoch 10/20\n",
    "# 800/800 [==============================] - 0s 87us/step - loss: 0.8768 - acc: 0.7263\n",
    "# Epoch 11/20\n",
    "# 800/800 [==============================] - 0s 65us/step - loss: 0.8361 - acc: 0.7375\n",
    "# Epoch 12/20\n",
    "# 800/800 [==============================] - 0s 110us/step - loss: 0.7891 - acc: 0.7437\n",
    "# Epoch 13/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 0.7556 - acc: 0.7563\n",
    "# Epoch 14/20\n",
    "# 800/800 [==============================] - 0s 74us/step - loss: 0.7123 - acc: 0.7787\n",
    "# Epoch 15/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 0.6776 - acc: 0.7900\n",
    "# Epoch 16/20\n",
    "# 800/800 [==============================] - 0s 66us/step - loss: 0.6432 - acc: 0.7963\n",
    "# Epoch 17/20\n",
    "# 800/800 [==============================] - 0s 61us/step - loss: 0.6190 - acc: 0.8100\n",
    "# Epoch 18/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 0.5978 - acc: 0.8188\n",
    "# Epoch 19/20\n",
    "# 800/800 [==============================] - 0s 60us/step - loss: 0.5537 - acc: 0.8337\n",
    "# Epoch 20/20\n",
    "# 800/800 [==============================] - 0s 64us/step - loss: 0.5374 - acc: 0.8463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link - https://github.com/priya-dwivedi/Music_Genre_Classification/blob/master/baseline_model_fma.ipynb\n",
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "    \n",
    "#this may not used at all    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    #################################################F1 score astesee predict_labels(...) theke \n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "  #  y_pred = clf.predict(features) ****Features is not defind for my dataset. if i can solve this line then\n",
    "#******************************************************{NameError: name 'y_pred' is not defined} will be \n",
    "#######################################################solved\n",
    "\n",
    "########################## ORIGIN CODE FIRST OCCURANCE OF FEATURES******************************\n",
    "\n",
    "#####################filepath = 'features.csv'\n",
    "################features = pd.read_csv(filepath, index_col=0,header=[0, 1, 2], skip_blank_lines=True )\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# features is pandas read_csv dictionary \n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='micro', pos_label = 1)\n",
    "\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    " \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "       #untill now no problem\n",
    "        \n",
    "        #### if i switched places between the train_predict and predict_labels\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    #may not work.....comment out this below section\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"F1 score for val set: {:.4f}.\".format(predict_labels(clf, X_val, y_val)))\n",
    "    print(\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier: \n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 800. . .\n",
      "Trained model in 0.2355 seconds\n",
      "Made predictions in 0.0000 seconds.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ad3160513336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclf_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_D\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n{}: \\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-ba6a390edb80>\u001b[0m in \u001b[0;36mtrain_predict\u001b[1;34m(clf, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Print the results of prediction for both training and testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 score for training set: {:.4f}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 score for val set: {:.4f}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 score for test set: {:.4f}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-ba6a390edb80>\u001b[0m in \u001b[0;36mpredict_labels\u001b[1;34m(clf, features, target)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Print and return results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Made predictions in {:.4f} seconds.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = DecisionTreeClassifier(random_state=10, max_depth =4)\n",
    "clf_B = SVC()\n",
    "clf_C = LogisticRegression()\n",
    "clf_D = RandomForestClassifier(random_state=10, max_depth=30, n_estimators=300, min_samples_leaf=6, min_impurity_decrease=0.0002,\n",
    "                     class_weight='balanced')\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D]:\n",
    "    print(\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    train_predict(clf, X_train, y_train, X_test, y_test)   # X_val turned to X_test, y_val to y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
